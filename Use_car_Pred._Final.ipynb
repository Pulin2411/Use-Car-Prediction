{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17ySheI_htiYQCWrz57whKAET801aEl9T","timestamp":1757958085350}],"mount_file_id":"17ySheI_htiYQCWrz57whKAET801aEl9T","authorship_tag":"ABX9TyMXKk2U/oSEqSjoLvZGZQ39"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"appaHDvuWu0H","executionInfo":{"status":"ok","timestamp":1757957027088,"user_tz":-330,"elapsed":28931,"user":{"displayName":"pulin shah","userId":"14164085806577758258"}},"outputId":"c02e6a04-9bff-4631-8cb6-34c68204ca69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using dataset: /content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/CAR DETAILS FROM CAR DEKHO.csv\n","Rows after cleaning: 3559\n","Columns available: ['name', 'year', 'selling_price', 'km_driven', 'fuel', 'seller_type', 'transmission', 'owner', 'car_age']\n","                       name  year  selling_price  km_driven    fuel seller_type transmission         owner  car_age\n","0             Maruti 800 AC  2007          60000      70000  Petrol  Individual       Manual   First Owner       18\n","1  Maruti Wagon R LXI Minor  2007         135000      50000  Petrol  Individual       Manual   First Owner       18\n","2      Hyundai Verna 1.6 SX  2012         600000     100000  Diesel  Individual       Manual   First Owner       13\n","3    Datsun RediGO T Option  2017         250000      46000  Petrol  Individual       Manual   First Owner        8\n","4     Honda Amaze VX i-DTEC  2014         450000     141000  Diesel  Individual       Manual  Second Owner       11\n","Saved EDA plots: ['/content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/car_price_plots/price_distribution.png', '/content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/car_price_plots/price_vs_age.png', '/content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/car_price_plots/price_vs_km.png']\n","[LinearRegression] R2=0.5073, MAE=173486.19, RMSE=59653174253.04\n","[Ridge] R2=0.5074, MAE=173476.23, RMSE=59642231146.40\n","[RandomForest] R2=0.5216, MAE=160216.14, RMSE=57917132400.11\n","[GradientBoosting] R2=0.5826, MAE=150462.71, RMSE=50537259751.28\n","[RandomForest_tuned] Best params: {'model__max_depth': 5, 'model__min_samples_split': 5, 'model__n_estimators': 200}\n","[RandomForest_tuned] R2=0.5792, MAE=150323.85, RMSE=50945477152.36\n","Model comparison (sorted by RMSE):\n","             model       r2           mae         rmse\n","  GradientBoosting 0.582591 150462.708471 5.053726e+10\n","RandomForest_tuned 0.579220 150323.849372 5.094548e+10\n","      RandomForest 0.521638 160216.140863 5.791713e+10\n","             Ridge 0.507390 173476.232631 5.964223e+10\n","  LinearRegression 0.507299 173486.193539 5.965317e+10\n","Saved Pred vs Actual plot to /content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/car_price_plots/pred_vs_actual_GradientBoosting.png\n","Feature importance saved to /content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/feature_importance.csv\n","                     feature  importance\n","                     car_age    0.369655\n","      transmission_Automatic    0.231715\n","                 fuel_Diesel    0.168533\n","                   km_driven    0.085905\n","         transmission_Manual    0.071470\n","                 fuel_Petrol    0.057242\n","      seller_type_Individual    0.007822\n","seller_type_Trustmark Dealer    0.002353\n","          owner_Second Owner    0.002242\n","           owner_First Owner    0.001452\n","Saved best model to /content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/best_model_GradientBoosting.joblib\n","Saved summary to /content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details/car_price_pipeline_summary.txt\n"]}],"source":["# used_car_price_pipeline.py\n","# Full pipeline for Used Car Price Prediction\n","# Designed to run in a notebook or as a script. Adjust CURRENT_YEAR if required.\n","\n","import os, glob, re\n","import numpy as np, pandas as pd, matplotlib.pyplot as plt, joblib\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LinearRegression, Ridge\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n","\n","# ---------- Config ----------\n","DATA_DIR = \"/content/drive/MyDrive/Project: Used Car Price Prediction using Vehicle Dataset/Car details\"\n","CURRENT_YEAR = 2025   # adjust if necessary\n","PLOT_DIR = os.path.join(DATA_DIR, \"car_price_plots\")\n","os.makedirs(PLOT_DIR, exist_ok=True)\n","# ----------------------------\n","\n","def find_dataset(data_dir=DATA_DIR):\n","    csvs = glob.glob(os.path.join(data_dir, \"*.csv\"))\n","    # prefer files with 'car' or 'car details' in name\n","    prioritized = [p for p in csvs if re.search(r\"car\", os.path.basename(p), re.I)]\n","    return prioritized[0] if prioritized else (csvs[0] if csvs else None)\n","\n","def standardize_column_names(df):\n","    # Lowercase and strip underscores/spaces\n","    df = df.copy()\n","    df.columns = [re.sub(r'[^0-9a-z_]', '_', re.sub(r'\\s+', '_', c.strip().lower())\n","    ) for c in df.columns]\n","    # map common variants to standard names\n","    colmap = {}\n","    name_variants = ['name', 'car_name', 'carname', 'name_of_car']\n","    year_variants = ['year', 'manufacture_year', 'yr']\n","    price_variants = ['selling_price','sellingprice','price','sell_price','sellingprice_in_rupees','selling_price_(in_rupees)']\n","    km_variants = ['km_driven','kms_driven','km_driven_','km_driven_', 'present_km', 'present_kms_driven', 'present_price', 'kms']\n","    fuel_variants = ['fuel','fuel_type','fueltype']\n","    seller_variants = ['seller_type','seller_type_','seller']\n","    trans_variants = ['transmission','trans','transmission_type']\n","    owner_variants = ['owner','ownership','owner_type']\n","\n","    def find_and_map(variants, target):\n","        for v in variants:\n","            matches = [c for c in df.columns if v == c or v in c]\n","            if matches:\n","                colmap[matches[0]] = target\n","                return True\n","        return False\n","\n","    find_and_map(name_variants, 'name')\n","    find_and_map(year_variants, 'year')\n","    find_and_map(price_variants, 'selling_price')\n","    # for km variants try best match (search for 'km' or 'kmdriven' etc)\n","    km_candidates = [c for c in df.columns if re.search(r'km|kms|kmdriven|kmdr', c)]\n","    if km_candidates:\n","        colmap[km_candidates[0]] = 'km_driven'\n","    find_and_map(fuel_variants, 'fuel')\n","    find_and_map(seller_variants, 'seller_type')\n","    find_and_map(trans_variants, 'transmission')\n","    find_and_map(owner_variants, 'owner')\n","\n","    df = df.rename(columns=colmap)\n","    return df\n","\n","def clean_price_column(x):\n","    if pd.isna(x): return np.nan\n","    if isinstance(x, (int, float)): return float(x)\n","    s = str(x).lower().strip()\n","    s = s.replace(\",\", \"\").replace(\"rs\", \"\").replace(\"inr\", \"\").strip()\n","    # handle lakhs/crores\n","    if \"lakh\" in s or \"lac\" in s:\n","        num = re.findall(r\"[\\d\\.]+\", s)\n","        if num:\n","            return float(num[0]) * 100000\n","    if \"crore\" in s:\n","        num = re.findall(r\"[\\d\\.]+\", s)\n","        if num:\n","            return float(num[0]) * 10000000\n","    # otherwise extract numeric\n","    num = re.findall(r\"[\\d\\.]+\", s)\n","    if num:\n","        return float(num[0])\n","    return np.nan\n","\n","def load_and_prepare(path):\n","    df = pd.read_csv(path, encoding='latin1')\n","    df = standardize_column_names(df)\n","    # Ensure expected columns exist\n","    expected = ['name','year','selling_price','km_driven','fuel','seller_type','transmission','owner']\n","    # Convert selling_price\n","    if 'selling_price' in df.columns:\n","        if df['selling_price'].dtype == object or not np.issubdtype(df['selling_price'].dtype, np.number):\n","            df['selling_price'] = df['selling_price'].apply(clean_price_column)\n","            # Heuristic: if median is small (<1000) try treat as lakhs -> convert to rupees\n","            if df['selling_price'].median() and df['selling_price'].median() < 1000:\n","                # only convert if original text didn't explicitly include 'lakh' or 'crore'\n","                if not df['selling_price'].astype(str).str.contains('lakh|lac|crore', case=False).any():\n","                    df['selling_price'] = df['selling_price'] * 100000\n","    # km_driven conversion\n","    if 'km_driven' in df.columns:\n","        if df['km_driven'].dtype == object:\n","            df['km_driven'] = df['km_driven'].astype(str).str.replace(\",\", \"\").str.extract(r\"(\\d+)\").astype(float)\n","    # year numeric\n","    if 'year' in df.columns:\n","        df['year'] = pd.to_numeric(df['year'], errors='coerce')\n","    # drop duplicates and rows without target\n","    df = df.drop_duplicates()\n","    df = df.dropna(subset=['selling_price'])\n","    # feature: car_age\n","    if 'year' in df.columns:\n","        df['car_age'] = CURRENT_YEAR - df['year']\n","    else:\n","        # if year not available try to parse from name (rare)\n","        df['car_age'] = np.nan\n","    # basic filtering\n","    df = df[df['car_age'].ge(0) & df['car_age'].le(60)]\n","    if 'km_driven' in df.columns:\n","        df = df[df['km_driven'].ge(0)]\n","    # remove top 0.5% price outliers\n","    if 'selling_price' in df.columns:\n","        upper = df['selling_price'].quantile(0.995)\n","        df = df[df['selling_price'] <= upper]\n","    return df\n","\n","def create_and_save_eda(df, plot_dir=PLOT_DIR):\n","    # price distribution\n","    plt.figure(figsize=(8,5))\n","    plt.hist(df['selling_price'], bins=50)\n","    plt.title(\"Selling Price Distribution\")\n","    plt.xlabel(\"Selling Price\")\n","    plt.ylabel(\"Count\")\n","    plt.tight_layout()\n","    p1 = os.path.join(plot_dir, \"price_distribution.png\")\n","    plt.savefig(p1)\n","    plt.close()\n","\n","    # price vs age\n","    if 'car_age' in df.columns:\n","        plt.figure(figsize=(8,5))\n","        plt.scatter(df['car_age'], df['selling_price'], s=6)\n","        plt.title(\"Selling Price vs Car Age\")\n","        plt.xlabel(\"Car Age (years)\")\n","        plt.ylabel(\"Selling Price\")\n","        plt.tight_layout()\n","        p2 = os.path.join(plot_dir, \"price_vs_age.png\")\n","        plt.savefig(p2)\n","        plt.close()\n","\n","    # price vs km_driven\n","    if 'km_driven' in df.columns:\n","        plt.figure(figsize=(8,5))\n","        plt.scatter(df['km_driven'], df['selling_price'], s=6)\n","        plt.title(\"Selling Price vs Km Driven\")\n","        plt.xlabel(\"Km Driven\")\n","        plt.ylabel(\"Selling Price\")\n","        plt.tight_layout()\n","        p3 = os.path.join(plot_dir, \"price_vs_km.png\")\n","        plt.savefig(p3)\n","        plt.close()\n","\n","    return [p for p in (p1, (p2 if 'car_age' in df.columns else None), (p3 if 'km_driven' in df.columns else None)) if p]\n","\n","def prepare_features(df):\n","    # features: baseline numeric + categorical set\n","    numeric_features = []\n","    if 'km_driven' in df.columns:\n","        numeric_features.append('km_driven')\n","    if 'car_age' in df.columns:\n","        numeric_features.append('car_age')\n","\n","    categorical_features = [c for c in ['fuel', 'seller_type', 'transmission', 'owner'] if c in df.columns]\n","\n","    X = df[numeric_features + categorical_features].copy()\n","    y = df['selling_price'].astype(float).copy()\n","\n","    # Fill categorical missing\n","    for c in categorical_features:\n","        X[c] = X[c].fillna('Unknown').astype(str)\n","\n","    # Preprocessor\n","    num_transformer = Pipeline([('scaler', StandardScaler())])\n","    cat_transformer = Pipeline([('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","    preprocessor = ColumnTransformer([\n","        ('num', num_transformer, numeric_features),\n","        ('cat', cat_transformer, categorical_features)\n","    ])\n","\n","    return X, y, preprocessor, numeric_features, categorical_features\n","\n","def train_and_evaluate(X, y, preprocessor, numeric_features, categorical_features):\n","    # Models to compare\n","    models = {\n","        'LinearRegression': LinearRegression(),\n","        'Ridge': Ridge(),\n","        'RandomForest': RandomForestRegressor(random_state=42, n_jobs=-1),\n","        'GradientBoosting': GradientBoostingRegressor(random_state=42)\n","    }\n","\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    results = []\n","    fitted = {}\n","    for name, model in models.items():\n","        pipe = Pipeline([('preprocessor', preprocessor), ('model', model)])\n","        pipe.fit(X_train, y_train)\n","        preds = pipe.predict(X_test)\n","        r2 = r2_score(y_test, preds)\n","        mae = mean_absolute_error(y_test, preds)\n","        rmse = mean_squared_error(y_test, preds) # Removed squared=False\n","        results.append({'model': name, 'r2': r2, 'mae': mae, 'rmse': rmse})\n","        fitted[name] = pipe\n","        print(f\"[{name}] R2={r2:.4f}, MAE={mae:.2f}, RMSE={rmse:.2f}\")\n","\n","    # Hyperparameter tuning example for RandomForest\n","    rf_pipe = Pipeline([('preprocessor', preprocessor), ('model', RandomForestRegressor(random_state=42, n_jobs=-1))])\n","    param_grid = {\n","        'model__n_estimators': [100, 200],\n","        'model__max_depth': [5, 10, None],\n","        'model__min_samples_split': [2, 5]\n","    }\n","    gs = GridSearchCV(rf_pipe, param_grid, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1)\n","    gs.fit(X_train, y_train)\n","    best_rf = gs.best_estimator_\n","    rf_preds = best_rf.predict(X_test)\n","    rf_r2 = r2_score(y_test, rf_preds)\n","    rf_mae = mean_absolute_error(y_test, rf_preds)\n","    rf_rmse = mean_squared_error(y_test, rf_preds) # Removed squared=False\n","    results.append({'model': 'RandomForest_tuned', 'r2': rf_r2, 'mae': rf_mae, 'rmse': rf_rmse})\n","    fitted['RandomForest_tuned'] = best_rf\n","    print(f\"[RandomForest_tuned] Best params: {gs.best_params_}\")\n","    print(f\"[RandomForest_tuned] R2={rf_r2:.4f}, MAE={rf_mae:.2f}, RMSE={rf_rmse:.2f}\")\n","\n","    results_df = pd.DataFrame(results).sort_values('rmse').reset_index(drop=True)\n","    return results_df, fitted, X_test, y_test\n","\n","def plot_pred_vs_actual(model_pipe, X_test, y_test, fname):\n","    y_pred = model_pipe.predict(X_test)\n","    plt.figure(figsize=(8,6))\n","    plt.scatter(y_test, y_pred, s=6)\n","    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], linewidth=2)\n","    plt.xlabel(\"Actual Selling Price\")\n","    plt.ylabel(\"Predicted Selling Price\")\n","    plt.title(\"Predicted vs Actual\")\n","    plt.tight_layout()\n","    plt.savefig(fname)\n","    plt.close()\n","\n","def extract_feature_importance(model_pipe, numeric_features, categorical_features):\n","    # Only works for tree-based models with feature_importances_\n","    try:\n","        # Get onehot encoder feature names\n","        ohe = model_pipe.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot']\n","        ohe_names = list(ohe.get_feature_names_out(categorical_features))\n","        feat_names = numeric_features + ohe_names\n","        importances = model_pipe.named_steps['model'].feature_importances_\n","        fi = pd.DataFrame({'feature': feat_names, 'importance': importances}).sort_values('importance', ascending=False)\n","        return fi\n","    except Exception:\n","        return None\n","\n","# ---------------- Main flow ----------------\n","dataset = find_dataset()\n","if dataset is None:\n","    raise FileNotFoundError(\"No CSV dataset found in /mnt/data. Upload your CSV and retry.\")\n","\n","print(\"Using dataset:\", dataset)\n","df = load_and_prepare(dataset)\n","print(\"Rows after cleaning:\", len(df))\n","print(\"Columns available:\", df.columns.tolist())\n","\n","# quick peek\n","print(df.head(5).to_string())\n","\n","# EDA plots (saved)\n","plots = create_and_save_eda(df)\n","print(\"Saved EDA plots:\", plots)\n","\n","# features & preprocessing\n","X, y, preprocessor, numeric_features, categorical_features = prepare_features(df)\n","\n","# ensure we have at least one numeric or categorical feature\n","if X.shape[1] == 0:\n","    raise ValueError(\"No usable features found after preparing dataset. Check dataset columns.\")\n","\n","results_df, fitted_models, X_test, y_test = train_and_evaluate(X, y, preprocessor, numeric_features, categorical_features)\n","\n","print(\"Model comparison (sorted by RMSE):\")\n","print(results_df.to_string(index=False))\n","\n","# Choose best model\n","best_row = results_df.iloc[0]\n","best_name = best_row['model']\n","best_model = fitted_models[best_name]\n","\n","# Save predicted vs actual\n","pred_plot_path = os.path.join(PLOT_DIR, f\"pred_vs_actual_{best_name}.png\")\n","plot_pred_vs_actual(best_model, X_test, y_test, pred_plot_path)\n","print(\"Saved Pred vs Actual plot to\", pred_plot_path)\n","\n","# Feature importance if available\n","fi = extract_feature_importance(best_model, numeric_features, categorical_features)\n","if fi is not None:\n","    fi_path = os.path.join(DATA_DIR, \"feature_importance.csv\")\n","    fi.to_csv(fi_path, index=False)\n","    print(\"Feature importance saved to\", fi_path)\n","    print(fi.head(10).to_string(index=False))\n","else:\n","    print(\"Feature importance not available for the selected best model (likely not tree-based).\")\n","\n","# Save best model\n","model_path = os.path.join(DATA_DIR, f\"best_model_{best_name}.joblib\")\n","joblib.dump(best_model, model_path)\n","print(\"Saved best model to\", model_path)\n","\n","# Save summary\n","summary = {\n","    \"dataset_file\": os.path.basename(dataset),\n","    \"rows_after_cleaning\": int(len(df)),\n","    \"features_used\": numeric_features + categorical_features,\n","    \"best_model\": best_name,\n","    \"best_model_metrics\": best_row.to_dict(),\n","    \"plots_dir\": PLOT_DIR,\n","    \"saved_model\": model_path\n","}\n","summary_txt = os.path.join(DATA_DIR, \"car_price_pipeline_summary.txt\")\n","with open(summary_txt, \"w\") as f:\n","    for k,v in summary.items():\n","        f.write(f\"{k}: {v}\\n\")\n","print(\"Saved summary to\", summary_txt)"]}]}
